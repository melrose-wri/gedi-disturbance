{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "is_executing": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected str, bytes or os.PathLike object, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpathlib\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Path\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mprocessing\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m degradation_overlap\n\u001B[0;32m----> 3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdata\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m spark_postgis\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdata\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m jrc_parser\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msrc\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m constants\n",
      "File \u001B[0;32m/opt/coiled/env/lib/python3.8/site-packages/src/data/spark_postgis.py:10\u001B[0m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mmath\u001B[39;00m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtyping\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Any, Dict\n\u001B[0;32m---> 10\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msrc\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m constants\n\u001B[1;32m     12\u001B[0m PARTITION_OPTS \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m([\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnumPartitions\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpartitionColumn\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlowerBound\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mupperBound\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[1;32m     15\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_spark\u001B[39m():\n",
      "File \u001B[0;32m/opt/coiled/env/lib/python3.8/site-packages/src/constants.py:33\u001B[0m\n\u001B[1;32m     30\u001B[0m LOG_PATH\u001B[38;5;241m.\u001B[39mmkdir(parents\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, exist_ok\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m     32\u001B[0m \u001B[38;5;66;03m#  Data related paths\u001B[39;00m\n\u001B[0;32m---> 33\u001B[0m DATA_PATH \u001B[38;5;241m=\u001B[39m \u001B[43mPath\u001B[49m\u001B[43m(\u001B[49m\u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgetenv\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mDATA_PATH\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     34\u001B[0m RESULTS_PATH \u001B[38;5;241m=\u001B[39m Path(os\u001B[38;5;241m.\u001B[39mgetenv(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRESULTS_PATH\u001B[39m\u001B[38;5;124m\"\u001B[39m))\n\u001B[1;32m     35\u001B[0m USER_PATH \u001B[38;5;241m=\u001B[39m Path(os\u001B[38;5;241m.\u001B[39mgetenv(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUSER_PATH\u001B[39m\u001B[38;5;124m\"\u001B[39m))\n",
      "File \u001B[0;32m/opt/coiled/env/lib/python3.8/pathlib.py:1042\u001B[0m, in \u001B[0;36mPath.__new__\u001B[0;34m(cls, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1040\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mcls\u001B[39m \u001B[38;5;129;01mis\u001B[39;00m Path:\n\u001B[1;32m   1041\u001B[0m     \u001B[38;5;28mcls\u001B[39m \u001B[38;5;241m=\u001B[39m WindowsPath \u001B[38;5;28;01mif\u001B[39;00m os\u001B[38;5;241m.\u001B[39mname \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnt\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m PosixPath\n\u001B[0;32m-> 1042\u001B[0m \u001B[38;5;28mself\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mcls\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_from_parts\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minit\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m   1043\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_flavour\u001B[38;5;241m.\u001B[39mis_supported:\n\u001B[1;32m   1044\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mNotImplementedError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcannot instantiate \u001B[39m\u001B[38;5;132;01m%r\u001B[39;00m\u001B[38;5;124m on your system\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1045\u001B[0m                               \u001B[38;5;241m%\u001B[39m (\u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m,))\n",
      "File \u001B[0;32m/opt/coiled/env/lib/python3.8/pathlib.py:683\u001B[0m, in \u001B[0;36mPurePath._from_parts\u001B[0;34m(cls, args, init)\u001B[0m\n\u001B[1;32m    678\u001B[0m \u001B[38;5;129m@classmethod\u001B[39m\n\u001B[1;32m    679\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_from_parts\u001B[39m(\u001B[38;5;28mcls\u001B[39m, args, init\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m):\n\u001B[1;32m    680\u001B[0m     \u001B[38;5;66;03m# We need to call _parse_args on the instance, so as to get the\u001B[39;00m\n\u001B[1;32m    681\u001B[0m     \u001B[38;5;66;03m# right flavour.\u001B[39;00m\n\u001B[1;32m    682\u001B[0m     \u001B[38;5;28mself\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mobject\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__new__\u001B[39m(\u001B[38;5;28mcls\u001B[39m)\n\u001B[0;32m--> 683\u001B[0m     drv, root, parts \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_parse_args\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    684\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_drv \u001B[38;5;241m=\u001B[39m drv\n\u001B[1;32m    685\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_root \u001B[38;5;241m=\u001B[39m root\n",
      "File \u001B[0;32m/opt/coiled/env/lib/python3.8/pathlib.py:667\u001B[0m, in \u001B[0;36mPurePath._parse_args\u001B[0;34m(cls, args)\u001B[0m\n\u001B[1;32m    665\u001B[0m     parts \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m a\u001B[38;5;241m.\u001B[39m_parts\n\u001B[1;32m    666\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 667\u001B[0m     a \u001B[38;5;241m=\u001B[39m \u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfspath\u001B[49m\u001B[43m(\u001B[49m\u001B[43ma\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    668\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(a, \u001B[38;5;28mstr\u001B[39m):\n\u001B[1;32m    669\u001B[0m         \u001B[38;5;66;03m# Force-cast str subclasses to str (issue #21127)\u001B[39;00m\n\u001B[1;32m    670\u001B[0m         parts\u001B[38;5;241m.\u001B[39mappend(\u001B[38;5;28mstr\u001B[39m(a))\n",
      "\u001B[0;31mTypeError\u001B[0m: expected str, bytes or os.PathLike object, not NoneType"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from src.processing import degradation_overlap\n",
    "from src.data import spark_postgis\n",
    "from src.data import jrc_parser\n",
    "from src import constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620f03148190e336",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f4b70e982937d6af",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6e2e2d84774e8b",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#shots_dir = 's3://gfw2-data/climate/European_height_carbon_model/gedi_coincident_shot/data/shots/'\n",
    "shots_dir = 's3://gfw2-data/climate/European_height_carbon_model/gedi_coincident_shot/data/dummy/'\n",
    "ecozone_dir = 's3://gfw2-data/climate/European_height_carbon_model/gedi_coincident_shot/data/vector/ecozone/'\n",
    "gadm_dir = 's3://gfw2-data/climate/European_height_carbon_model/gedi_coincident_shot/data/vector/country/'\n",
    "sdpt_dir = 's3://gfw2-data/climate/European_height_carbon_model/gedi_coincident_shot/data/vector/sdpt/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2a878bbc6c9b95",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da912ceaa4b6a024",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Step 1: Get a Spark Session "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94aa54f70e566111",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Create a spark session\n",
    "spark =  .get_spark()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7124b8e036b8b16b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Step 2: Create Shots Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da772671f7b2118a",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "shots_df = degradation_overlap.get_shots_df(spark, shots_dir)  #TODO: Lat and long are flipped, make sure geom vs geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140c56cd26105e66",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Check the geometries from the first two rows in the shots data frame\n",
    "shots_df.show(n=2)\n",
    "shots_df.select(['t1_geom', 't2_geom']).show(n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea91d180788019b9",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Step 3: Convert Shot Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b3bdf5bd637a40",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "shots_df = jrc_parser.convert_shot_dates(shots_df)\n",
    "shots_df.createOrReplaceTempView(\"gedi_shots\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d9930b853b4674",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Check the dates from the first two rows in the shots data frame\n",
    "shots_df.select(['t1_year', 't2_year']).show(n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9417f89ee260e511",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Step 4: Overlay Ecozone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c8c3b4206f628f",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Create ecozone dataframe\n",
    "def get_ecozone_df(spark, ecozone_dir):\n",
    "    ecozone_df = spark.read.parquet(ecozone_dir.as_posix())\n",
    "    ecozone_df.createOrReplaceTempView(\"ecozones\")\n",
    "    ecozone_df = spark.sql(\n",
    "        \"SELECT *, ST_GeomFromWKB(geometry) AS geom FROM ecozones\"\n",
    "    )\n",
    "    ecozone_df = ecozone_df.drop(\"geometry\")\n",
    "    ecozone_df.createOrReplaceTempView(\"ecozones\")\n",
    "    return ecozone_df\n",
    "\n",
    "ecozone_df = get_ecozone_df(spark, ecozone_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475e5822b7db5436",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Check the first ten rows in the ecozone data frame\n",
    "ecozone_df.show(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881fd09069bf501b",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Join ecozones to shots dataframe\n",
    "ecozone_join_query = f\"\"\"\n",
    "    SELECT s.*, f.emisEcozon AS emisEcozon, f.gainEcozon AS gainEcozon, f.GEZ_TERM AS GEZ_TERM\n",
    "    FROM gedi_shots as s INNER JOIN ecozones as f\n",
    "    ON ST_Contains(f.geom, s.t2_geom)\n",
    "\"\"\"\n",
    "\n",
    "shots_df = spark.sql(ecozone_join_query)\n",
    "shots_df.createOrReplaceTempView(\"gedi_shots\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5cc0f05770815f",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Check the ecozone columns from the first two rows in the shots data frame\n",
    "shots_df.select(['emisEcozon', 'gainEcozon', 'GEZ_TERM']).show(n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55213ec66251f0e1",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Step 5: Overlay Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9674b2dc10a733f",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#TODO: Update with new GADM\n",
    "#Create GADM dataframe\n",
    "def get_gadm_df(spark, gadm_dir):\n",
    "    gadm_df = spark.read.parquet(gadm_dir.as_posix())\n",
    "    gadm_df.createOrReplaceTempView(\"gadm\")\n",
    "    gadm_df = spark.sql(\n",
    "        \"SELECT *, ST_GeomFromWKB(geometry) AS geom FROM gadm\"\n",
    "    )\n",
    "    gadm_df = gadm_df.drop(\"geometry\")\n",
    "    gadm_df.createOrReplaceTempView(\"gadm\")\n",
    "    return gadm_df\n",
    "\n",
    "gadm_df = get_gadm_df(spark, gadm_dir)\n",
    "\n",
    "\n",
    "\n",
    "shots_df.show(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff878e451695232",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Check the first ten rows in the gadm data frame\n",
    "gadm_df.show(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b421e0a4e3b964",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Join GADM to shots dataframe\n",
    "gadm_join_query = f\"\"\"\n",
    "    SELECT s.*, f.iso AS country\n",
    "    FROM gedi_shots as s INNER JOIN gadm as f\n",
    "    ON ST_Contains(f.geom, s.t2_geom)\n",
    "\"\"\"\n",
    "\n",
    "shots_df = spark.sql(gadm_join_query)\n",
    "shots_df.createOrReplaceTempView(\"gedi_shots\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9d975ebba04fce",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Check the gadm column from the first two rows in the shots data frame\n",
    "shots_df.select(['country']).show(n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e53ba35558551a",
   "metadata": {
    "collapsed": false
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
